{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrosspet/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from precommit_analysis.keras_mnist_example import prepare_data, create_mnist_cnn_model\n",
    "from precommit_analysis.generators import sparse_mnist_generator_nonzero, eval_generator\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test, input_shape = prepare_data(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the judge\n",
    "\n",
    "- sparse MNIST classifier\n",
    "- 6 non-zero pixels are randomly sampled from an input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_generator = sparse_mnist_generator_nonzero(x_train, y_train, batch_size, sparsity=6)\n",
    "val_data_generator = sparse_mnist_generator_nonzero(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    batch_size=x_test.shape[0],\n",
    "    sparsity=6,\n",
    "    shuffle=False\n",
    ")\n",
    "val_data = next(val_data_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First train a judge on only 5k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 256s 256ms/step - loss: 1.6545 - acc: 0.4302 - val_loss: 1.4303 - val_acc: 0.5097\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 254s 254ms/step - loss: 1.5218 - acc: 0.4699 - val_loss: 1.3892 - val_acc: 0.5206\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 270s 270ms/step - loss: 1.4913 - acc: 0.4799 - val_loss: 1.3654 - val_acc: 0.5261\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 261s 261ms/step - loss: 1.4786 - acc: 0.4850 - val_loss: 1.3547 - val_acc: 0.5333\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 261s 261ms/step - loss: 1.4656 - acc: 0.4898 - val_loss: 1.3435 - val_acc: 0.5344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f61ae96a668>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge = create_mnist_cnn_model(num_classes, input_shape)\n",
    "judge.fit_generator(training_data_generator,\n",
    "          steps_per_epoch=1000,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge.save('model_sparse_mnist_generator_nonzero_5k.h5py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a better judge on 30k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 268s 268ms/step - loss: 1.6560 - acc: 0.4282 - val_loss: 1.4424 - val_acc: 0.4989\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 270s 270ms/step - loss: 1.5235 - acc: 0.4681 - val_loss: 1.3988 - val_acc: 0.5193\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 266s 266ms/step - loss: 1.4985 - acc: 0.4776 - val_loss: 1.3772 - val_acc: 0.5220\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 259s 259ms/step - loss: 1.4784 - acc: 0.4843 - val_loss: 1.3614 - val_acc: 0.5286\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 253s 253ms/step - loss: 1.4679 - acc: 0.4893 - val_loss: 1.3561 - val_acc: 0.5306\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 259s 259ms/step - loss: 1.4545 - acc: 0.4950 - val_loss: 1.3465 - val_acc: 0.5325\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 253s 253ms/step - loss: 1.4550 - acc: 0.4943 - val_loss: 1.3363 - val_acc: 0.5359\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 253s 253ms/step - loss: 1.4492 - acc: 0.4948 - val_loss: 1.3375 - val_acc: 0.5354\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 252s 252ms/step - loss: 1.4380 - acc: 0.5006 - val_loss: 1.3310 - val_acc: 0.5437\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 256s 256ms/step - loss: 1.4367 - acc: 0.4991 - val_loss: 1.3234 - val_acc: 0.5392\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 258s 258ms/step - loss: 1.4225 - acc: 0.5039 - val_loss: 1.3166 - val_acc: 0.5434\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 253s 253ms/step - loss: 1.4242 - acc: 0.5055 - val_loss: 1.3195 - val_acc: 0.5418\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 256s 256ms/step - loss: 1.4220 - acc: 0.5072 - val_loss: 1.3178 - val_acc: 0.5409\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 269s 269ms/step - loss: 1.4222 - acc: 0.5046 - val_loss: 1.3131 - val_acc: 0.5460\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 258s 258ms/step - loss: 1.4192 - acc: 0.5036 - val_loss: 1.3128 - val_acc: 0.5467\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 265s 265ms/step - loss: 1.4148 - acc: 0.5070 - val_loss: 1.3049 - val_acc: 0.5479\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 1.4132 - acc: 0.5091 - val_loss: 1.3011 - val_acc: 0.5466\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 257s 257ms/step - loss: 1.4096 - acc: 0.5072 - val_loss: 1.3040 - val_acc: 0.5475\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 262s 262ms/step - loss: 1.4087 - acc: 0.5080 - val_loss: 1.2964 - val_acc: 0.5509\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 1.4098 - acc: 0.5097 - val_loss: 1.2965 - val_acc: 0.5557\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 246s 246ms/step - loss: 1.4061 - acc: 0.5111 - val_loss: 1.2995 - val_acc: 0.5520\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 1.4009 - acc: 0.5117 - val_loss: 1.2925 - val_acc: 0.5555\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 258s 258ms/step - loss: 1.3942 - acc: 0.5150 - val_loss: 1.2887 - val_acc: 0.5529\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 259s 259ms/step - loss: 1.3959 - acc: 0.5147 - val_loss: 1.2898 - val_acc: 0.5522\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 256s 256ms/step - loss: 1.3939 - acc: 0.5157 - val_loss: 1.2872 - val_acc: 0.5553\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 254s 254ms/step - loss: 1.3932 - acc: 0.5155 - val_loss: 1.2838 - val_acc: 0.5581\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 257s 257ms/step - loss: 1.3871 - acc: 0.5181 - val_loss: 1.2816 - val_acc: 0.5565\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 255s 255ms/step - loss: 1.3869 - acc: 0.5187 - val_loss: 1.2775 - val_acc: 0.5593\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 254s 254ms/step - loss: 1.3832 - acc: 0.5205 - val_loss: 1.2793 - val_acc: 0.5583\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 252s 252ms/step - loss: 1.3827 - acc: 0.5183 - val_loss: 1.2749 - val_acc: 0.5602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c22ff5f28>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge = create_mnist_cnn_model(num_classes, input_shape)\n",
    "judge.fit_generator(training_data_generator,\n",
    "          steps_per_epoch=1000,\n",
    "          epochs=30,\n",
    "          verbose=1,\n",
    "          validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge.save('model_sparse_mnist_generator_nonzero_30k.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
