{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrosspet/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import prepare_data, create_mnist_cnn_model, eval_generator, eval_precommit_generator, sparse_mnist_generator_nonzero, \n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, input_shape = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_generator = sparse_mnist_generator_nonzero(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    batch_size=x_test.shape[0],\n",
    "    sparsity=6,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval judge alone\n",
    "\n",
    "- judge is a sparse MNIST classifier\n",
    "- 6 non-zero pixels are randomly sampled from an input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge - 5k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = create_mnist_cnn_model(num_classes, input_shape)\n",
    "judge.load_weights('model_sparse_mnist_generator_nonzero_5k.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 52.99%\n",
      "variance: 9.043600E-06\n"
     ]
    }
   ],
   "source": [
    "# judge samples 6 pixels on random -> we need to see more runs and look at mean and variance\n",
    "accuracies = eval_generator(val_data_generator, judge, num_repetitions=10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge - 30k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = create_mnist_cnn_model()\n",
    "judge.load_weights('model_sparse_mnist_generator_nonzero_30k.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 55.51%\n",
      "variance: 8.398400E-06\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_generator(val_data_generator, judge, num_repetitions=10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random pre-commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge - 5k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 87.36%\n",
      "variance: 7.724500E-06\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_generator(val_data_generator, judge, num_repetitions=10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge - 30k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.31%\n",
      "variance: 8.738100E-06\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_generator(val_data_generator, judge, num_repetitions=10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial precommit\n",
    "\n",
    "- take the best possible classifier of MNIST digits\n",
    "- and use it's 2nd most probable class as the adversarial choice for pre-commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge - 5k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model = create_mnist_cnn_model()\n",
    "adversarial_model.load_weights('model_mnist_12epochs.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 79.43%\n",
      "variance: 5.800400E-06\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge - 30k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 80.77%\n",
      "variance: 5.198500E-06\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with not so little trained adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model_1epoch = create_mnist_cnn_model()\n",
    "adversarial_model_1epoch.load_weights('model_mnist_30ksamples.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = adversarial_model_1epoch.predict(x_test)\n",
    "predictions.sort(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.8919548e-05\n",
      "8.44388e-05\n",
      "0.00015061667\n",
      "0.00030424772\n",
      "0.00067134533\n",
      "0.0014521435\n",
      "0.004261467\n",
      "0.021739153\n",
      "0.9300379\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print((predictions[:, i+1] - predictions[:, i]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7768, 0.7786, 0.778, 0.7788, 0.7737, 0.7723, 0.7819, 0.7757, 0.7794, 0.7774]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77726"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.076400000000022e-06"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge (30k batches, 56%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 80.60%\n",
      "variance: 8.182900E-06\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with not so well trained adversary (1epoch adam 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model_1epoch = create_mnist_cnn_model()\n",
    "adversarial_model_1epoch.load_weights('model_mnist_1epoch_adam1e-6.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = adversarial_model_1epoch.predict(x_test)\n",
    "predictions.sort(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0057919375\n",
      "0.0027946897\n",
      "0.0021697192\n",
      "0.0017012045\n",
      "0.0017048022\n",
      "0.0016837975\n",
      "0.001756748\n",
      "0.0025757554\n",
      "0.003859542\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print((predictions[:, i+1] - predictions[:, i]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8402,\n",
       " 0.8337,\n",
       " 0.8327,\n",
       " 0.8316,\n",
       " 0.8342,\n",
       " 0.8296,\n",
       " 0.8282,\n",
       " 0.8332,\n",
       " 0.8342,\n",
       " 0.8344]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8331999999999999"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.345999999999903e-06"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge (30k batches, 56%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 84.98%\n",
      "variance: 1.032250E-05\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with not so well trained adversary (1epoch adam 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model_1epoch = create_mnist_cnn_model()\n",
    "adversarial_model_1epoch.load_weights('model_mnist_1epoch_adam1e-5.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = adversarial_model_1epoch.predict(x_test)\n",
    "predictions.sort(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007946745\n",
      "0.0075184875\n",
      "0.0073646028\n",
      "0.009293356\n",
      "0.0102790715\n",
      "0.015551019\n",
      "0.025924066\n",
      "0.050632354\n",
      "0.3099722\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print((predictions[:, i+1] - predictions[:, i]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7416,\n",
       " 0.7402,\n",
       " 0.7439,\n",
       " 0.7388,\n",
       " 0.7387,\n",
       " 0.7363,\n",
       " 0.7379,\n",
       " 0.7353,\n",
       " 0.7394,\n",
       " 0.7348]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73869"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.136900000000057e-06"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1epoch of adam 1e-5 with improved judge 30k batches and 56%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model_1epoch = create_mnist_cnn_model()\n",
    "adversarial_model_1epoch.load_weights('model_mnist_1epoch_adam1e-5.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7492,\n",
       " 0.7533,\n",
       " 0.7464,\n",
       " 0.7598,\n",
       " 0.7544,\n",
       " 0.7539,\n",
       " 0.7546,\n",
       " 0.7566,\n",
       " 0.7575,\n",
       " 0.7556]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7541300000000001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3686100000000143e-05"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with not so well trained adversary (1epoch adam 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model_1epoch = create_mnist_cnn_model()\n",
    "adversarial_model_1epoch.load_weights('model_mnist_1epoch_adam5e-5.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = adversarial_model_1epoch.predict(x_test)\n",
    "predictions.sort(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00020120015\n",
      "0.00028793706\n",
      "0.0005427765\n",
      "0.00092903955\n",
      "0.0017772022\n",
      "0.003246927\n",
      "0.008957823\n",
      "0.035949793\n",
      "0.86433595\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print((predictions[:, i+1] - predictions[:, i]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7547, 0.7506, 0.7519, 0.7528, 0.7489, 0.7464, 0.7517, 0.7571, 0.752, 0.7568]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75229"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.916900000000071e-06"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge (30k batches, 56%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 76.28%\n",
      "variance: 1.054410E-05\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with not so well trained adversary (1epoch adam 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model_1epoch = create_mnist_cnn_model()\n",
    "adversarial_model_1epoch.load_weights('model_mnist_1epoch_adam1e-4.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = adversarial_model_1epoch.predict(x_test)\n",
    "predictions.sort(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00020377744\n",
      "0.00028670774\n",
      "0.0004772872\n",
      "0.00090709276\n",
      "0.0016539244\n",
      "0.0031683906\n",
      "0.008767544\n",
      "0.035903785\n",
      "0.8663495\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print((predictions[:, i+1] - predictions[:, i]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.75, 0.7513, 0.7528, 0.7493, 0.7477, 0.756, 0.7439, 0.7553, 0.7452, 0.7541]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75056"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.533239999999999e-05"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge (30k batches, 56%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 76.50%\n",
      "variance: 2.174610E-05\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with not so well trained adversary (15k samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model_1epoch = create_mnist_cnn_model()\n",
    "adversarial_model_1epoch.load_weights('model_mnist_15ksamples.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = adversarial_model_1epoch.predict(x_test)\n",
    "predictions.sort(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000103093334\n",
      "0.00016556526\n",
      "0.00026611346\n",
      "0.0005115029\n",
      "0.0009563338\n",
      "0.0020637854\n",
      "0.006247513\n",
      "0.028183825\n",
      "0.90365833\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print((predictions[:, i+1] - predictions[:, i]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7588, 0.7614, 0.7554, 0.7685, 0.7638, 0.7681, 0.756, 0.7645, 0.7537, 0.7533]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7603500000000001"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9646499999999944e-05"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge (30k batches, 56%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 77.42%\n",
      "variance: 1.449610E-05\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with not so well trained adversary (10k samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model_1epoch = create_mnist_cnn_model()\n",
    "adversarial_model_1epoch.load_weights('model_mnist_10ksamples.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = adversarial_model_1epoch.predict(x_test)\n",
    "predictions.sort(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00012411905\n",
      "0.00020309819\n",
      "0.00037283497\n",
      "0.000741312\n",
      "0.0013381963\n",
      "0.0029087411\n",
      "0.007879715\n",
      "0.035496786\n",
      "0.87621325\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print((predictions[:, i+1] - predictions[:, i]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7579, 0.7578, 0.7483, 0.761, 0.7533, 0.752, 0.7501, 0.749, 0.7486, 0.7531]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7531100000000001"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7788900000000063e-05"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge (30k batches, 56%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 76.82%\n",
      "variance: 1.452840E-05\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with not so well trained adversary (7.5k samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model_1epoch = create_mnist_cnn_model()\n",
    "adversarial_model_1epoch.load_weights('model_mnist_7500samples.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = adversarial_model_1epoch.predict(x_test)\n",
    "predictions.sort(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00026031732\n",
      "0.00039710922\n",
      "0.00069402973\n",
      "0.0012838073\n",
      "0.002340322\n",
      "0.0048589576\n",
      "0.013530184\n",
      "0.06532739\n",
      "0.777313\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print((predictions[:, i+1] - predictions[:, i]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7656, 0.7574, 0.7604, 0.7619, 0.7589, 0.7648, 0.7674, 0.7593, 0.763, 0.7647]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76234"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.772400000000029e-06"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge (30k batches, 56%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 77.24%\n",
      "variance: 1.531050E-05\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with even less trained adversary (5k samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model_1epoch = create_mnist_cnn_model()\n",
    "adversarial_model_1epoch.load_weights('model_mnist_5ksamples.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = adversarial_model_1epoch.predict(x_test)\n",
    "predictions.sort(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007173434\n",
      "0.00081278256\n",
      "0.0011765662\n",
      "0.001964301\n",
      "0.0031793755\n",
      "0.0070958748\n",
      "0.018775087\n",
      "0.08195718\n",
      "0.6960923\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print((predictions[:, i+1] - predictions[:, i]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7862,\n",
       " 0.7833,\n",
       " 0.7875,\n",
       " 0.7801,\n",
       " 0.7819,\n",
       " 0.7828,\n",
       " 0.7862,\n",
       " 0.7859,\n",
       " 0.7769,\n",
       " 0.7806]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7831400000000001"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.016639999999997e-05"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge (30k batches, 56%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 80.12%\n",
      "variance: 2.667810E-05\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Even worse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model_1epoch = create_mnist_cnn_model()\n",
    "adversarial_model_1epoch.load_weights('model_mnist_500samples.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = adversarial_model_1epoch.predict(x_test)\n",
    "predictions.sort(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019914161\n",
      "0.008608694\n",
      "0.010177943\n",
      "0.00808178\n",
      "0.010024752\n",
      "0.01380032\n",
      "0.019552795\n",
      "0.032029033\n",
      "0.047684215\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print((predictions[:, i+1] - predictions[:, i]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8403, 0.8454, 0.8417, 0.8419, 0.8438, 0.846, 0.8466, 0.8438, 0.8438, 0.8393]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8432599999999999"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.284399999999954e-06"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge (30k batches, 56%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 85.61%\n",
      "variance: 4.547600E-06\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversarial_model_1epoch, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal adversary - perfect knowledge of judge\n",
    "\n",
    "- trivial\n",
    "- choose judge's predicted categories as long as they are not true\n",
    "- otherwise take the 2nd most probable class according to the judge and hope for a tie, which is a loose in our setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_optimal_adversary_generator(val_data_generator, judge, num_repetitions):\n",
    "    # calculate true categories\n",
    "    data_x_sparse, data_y = next(val_data_generator)\n",
    "    true_categories = data_y.argmax(axis=1)\n",
    "    accuracies = []\n",
    "    # we have a noisy judge, so we need repetitions to find variance\n",
    "    for i in range(num_repetitions):\n",
    "        data_x_sparse, _ = next(val_data_generator)\n",
    "        \n",
    "        predictions = judge.predict(data_x_sparse)\n",
    "        \n",
    "        adversary = predictions.argsort(axis=1)\n",
    "        adversary_precommit = adversary[:, -1]\n",
    "        \n",
    "        equal_selections = adversary_precommit == true_categories\n",
    "        adversary_precommit[equal_selections] = adversary[equal_selections, -2]\n",
    "        \n",
    "        acc = eval_judge(predictions, true_categories, adversary_precommit)\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5318, 0.5293, 0.526, 0.533, 0.5296, 0.5278, 0.5264, 0.5256, 0.5315, 0.5283]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = eval_optimal_adversary_generator(val_data_generator, judge, 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52893"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.974100000000048e-06"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge (30k batches, 56%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 55.62%\n",
      "variance: 3.117450E-05\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_optimal_adversary_generator(val_data_generator, judge, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- much of the gain in judge's accuracy can be explained with the pre-commit only, without the actual debate between the 2 agents\n",
    "- adversarial precommit indeed managed to decrease the judge's accuracy compared to random precommit\n",
    "- on the other hand, debate seems to be a useful tool for mitigating the effect of adversary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| precommit type | judge 5k | judge 30k |\n",
    "|-----------------------|----------|----------|\n",
    "| random | 87.35% | 88.31% |\n",
    "| adversarial_top | 79.43% | 80.77% |\n",
    "| adversarial_30k | 77.72% | 80.60% |\n",
    "| adversarial_15k | 76.04% | 77.42% |\n",
    "| adversarial_10k | 75.31% | 76.82% |\n",
    "| adversarial_7.5k | 76.23% | 77.24% |\n",
    "| adversarial_5k | 78.31% | 80.12% |\n",
    "| adversarial_500 | 84.33% | 85.61% |\n",
    "|-----------------------|----------|----------|\n",
    "| adversarial_adam 1e-6 | 83.32% | 84.98% |\n",
    "| adversarial_adam 5e-5 | 75.23% | 76.28% \n",
    "| adversarial_adam 1e-5| 73.87% | 75.41% ||\n",
    "| adversarial_adam 1e-4| 75.06% | 76.50% |\n",
    "|-----------------------|----------|----------|\n",
    "| perfect knowledge | 52.89% | 55.62% |\n",
    "|-----------------------|----------|----------|\n",
    "| none / baseline | 52.99% | 55.51% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge as a means to resolve disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_pred, y_true):\n",
    "    correct = (y_pred == y_true).sum()\n",
    "    print('correct: ', correct)\n",
    "    return correct / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_agent_a = create_mnist_cnn_model()\n",
    "super_agent_a.load_weights('model_mnist_1epoch_adam1e-5.h5py')\n",
    "\n",
    "super_agent_b = create_mnist_cnn_model()\n",
    "super_agent_b.load_weights('model_mnist_1epoch_adam5e-5.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_sparse, data_y = next(val_data_generator)\n",
    "\n",
    "true_categories = data_y.argmax(axis=1)\n",
    "\n",
    "predictions_a = super_agent_a.predict(x_test).argmax(axis=1)\n",
    "predictions_b = super_agent_b.predict(x_test).argmax(axis=1)\n",
    "predictions_judge = judge.predict(data_x_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreement = predictions_a != predictions_b\n",
    "\n",
    "resolution = predictions_judge[disagreement, predictions_a[disagreement]] > predictions_judge[disagreement, predictions_b[disagreement]]\n",
    "\n",
    "res = predictions_b[disagreement]\n",
    "res[resolution] = predictions_a[disagreement][resolution]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44427363566487316"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(res, true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0722521137586472"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_a[disagreement], true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8262874711760184"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_b[disagreement], true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8387"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_a, true_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9368"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_b, true_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_category_judge = predictions_judge.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22982321291314373"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predicted_category_judge[disagreement], true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1301"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disagreement.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents of the same power (just different seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_agent_a = create_mnist_cnn_model()\n",
    "super_agent_a.load_weights('model_mnist_1epoch_adam5e-5_2.h5py')\n",
    "\n",
    "super_agent_b = create_mnist_cnn_model()\n",
    "super_agent_b.load_weights('model_mnist_1epoch_adam5e-5.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_sparse, data_y = next(val_data_generator)\n",
    "\n",
    "true_categories = data_y.argmax(axis=1)\n",
    "\n",
    "predictions_a = super_agent_a.predict(x_test).argmax(axis=1)\n",
    "predictions_b = super_agent_b.predict(x_test).argmax(axis=1)\n",
    "predictions_judge = judge.predict(data_x_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreement = predictions_a != predictions_b\n",
    "\n",
    "resolution = predictions_judge[disagreement, predictions_a[disagreement]] > predictions_judge[disagreement, predictions_b[disagreement]]\n",
    "\n",
    "res = predictions_b[disagreement]\n",
    "res[resolution] = predictions_a[disagreement][resolution]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37950138504155123"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(res, true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23822714681440443"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_a[disagreement], true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6232686980609419"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_b[disagreement], true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9229"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_a, true_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9368"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_b, true_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_category_judge = predictions_judge.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21329639889196675"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predicted_category_judge[disagreement], true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disagreement.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_combined = predictions_a.copy()\n",
    "all_preds_combined[disagreement] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  9280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.928"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(all_preds_combined, true_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
