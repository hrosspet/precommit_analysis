{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrosspet/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import prepare_data, create_mnist_cnn_model, eval_generator, eval_precommit_generator, sparse_mnist_generator_nonzero, eval_precommit_adversarial_generator, eval_optimal_adversary_generator\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, input_shape = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_generator = sparse_mnist_generator_nonzero(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    batch_size=x_test.shape[0],\n",
    "    sparsity=6,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval judge alone\n",
    "\n",
    "- judge is a sparse MNIST classifier\n",
    "- 6 non-zero pixels are randomly sampled from an input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge - 5k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = create_mnist_cnn_model(num_classes, input_shape)\n",
    "judge.load_weights('model_sparse_mnist_generator_nonzero_5k.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 52.99%\n",
      "variance: 9.043600E-06\n"
     ]
    }
   ],
   "source": [
    "# judge samples 6 pixels on random -> we need to see more runs and look at mean and variance\n",
    "accuracies = eval_generator(val_data_generator, judge, num_repetitions=10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge - 30k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = create_mnist_cnn_model()\n",
    "judge.load_weights('model_sparse_mnist_generator_nonzero_30k.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 55.51%\n",
      "variance: 8.398400E-06\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_generator(val_data_generator, judge, num_repetitions=10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random pre-commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge - 5k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 87.36%\n",
      "variance: 7.724500E-06\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_generator(val_data_generator, judge, num_repetitions=10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge - 30k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.31%\n",
      "variance: 8.738100E-06\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_generator(val_data_generator, judge, num_repetitions=10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial precommit\n",
    "\n",
    "- evaluate the best adversary, which was found in train_adversary.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge - 5k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary = create_mnist_cnn_model()\n",
    "adversary.load_weights('model_mnist_1epoch_adam1e-5.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 73.87%\n",
      "variance: 7.136900E-06\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversary, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge - 30k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 75.41%\n",
      "variance: 1.368610E-05\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_precommit_adversarial_generator(x_test, val_data_generator, judge, adversary, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal adversary - perfect knowledge of judge\n",
    "\n",
    "- with perfect knowledge of the judge it's trivial to find an optimal adversarial pre-commit class\n",
    "- choose judge's predicted categories as long as they are not true\n",
    "- otherwise take the 2nd most probable class according to the judge and hope for a tie, which is a loose in our setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge - 5k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 52.89%\n",
      "variance: 5.974100E-06\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_optimal_adversary_generator(val_data_generator, judge, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better judge - 30k batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 55.62%\n",
      "variance: 3.117450E-05\n"
     ]
    }
   ],
   "source": [
    "accuracies = eval_optimal_adversary_generator(val_data_generator, judge, 10)\n",
    "print('accuracy: %.2f%%' % (100 * np.mean(accuracies)))\n",
    "print('variance: %E' % np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- much of the gain in judge's accuracy can be explained with the pre-commit only, without the actual debate between the 2 agents\n",
    "- adversarial precommit indeed managed to decrease the judge's accuracy compared to random precommit\n",
    "- on the other hand, debate seems to be a useful tool for mitigating the effect of adversary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| precommit type | judge 5k | judge 30k |\n",
    "|-----------------------|----------|----------|\n",
    "| random | 87.35% | 88.31% |\n",
    "| adversarial_top | 79.43% | 80.77% |\n",
    "| adversarial_30k | 77.72% | 80.60% |\n",
    "| adversarial_15k | 76.04% | 77.42% |\n",
    "| adversarial_10k | 75.31% | 76.82% |\n",
    "| adversarial_7.5k | 76.23% | 77.24% |\n",
    "| adversarial_5k | 78.31% | 80.12% |\n",
    "| adversarial_500 | 84.33% | 85.61% |\n",
    "|-----------------------|----------|----------|\n",
    "| adversarial_adam 1e-6 | 83.32% | 84.98% |\n",
    "| adversarial_adam 5e-5 | 75.23% | 76.28% \n",
    "| **adversarial_adam 1e-5** | **73.87%** | **75.41%** |\n",
    "| adversarial_adam 1e-4| 75.06% | 76.50% |\n",
    "|-----------------------|----------|----------|\n",
    "| perfect knowledge | 52.89% | 55.62% |\n",
    "|-----------------------|----------|----------|\n",
    "| none / baseline | 52.99% | 55.51% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge as a means to resolve disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_pred, y_true):\n",
    "    correct = (y_pred == y_true).sum()\n",
    "    print('correct: ', correct)\n",
    "    return correct / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_agent_a = create_mnist_cnn_model()\n",
    "super_agent_a.load_weights('model_mnist_1epoch_adam1e-5.h5py')\n",
    "\n",
    "super_agent_b = create_mnist_cnn_model()\n",
    "super_agent_b.load_weights('model_mnist_1epoch_adam5e-5.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_sparse, data_y = next(val_data_generator)\n",
    "\n",
    "true_categories = data_y.argmax(axis=1)\n",
    "\n",
    "predictions_a = super_agent_a.predict(x_test).argmax(axis=1)\n",
    "predictions_b = super_agent_b.predict(x_test).argmax(axis=1)\n",
    "predictions_judge = judge.predict(data_x_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreement = predictions_a != predictions_b\n",
    "\n",
    "resolution = predictions_judge[disagreement, predictions_a[disagreement]] > predictions_judge[disagreement, predictions_b[disagreement]]\n",
    "\n",
    "res = predictions_b[disagreement]\n",
    "res[resolution] = predictions_a[disagreement][resolution]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44427363566487316"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(res, true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0722521137586472"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_a[disagreement], true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8262874711760184"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_b[disagreement], true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8387"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_a, true_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9368"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_b, true_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_category_judge = predictions_judge.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22982321291314373"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predicted_category_judge[disagreement], true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1301"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disagreement.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents of the same power (just different seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_agent_a = create_mnist_cnn_model()\n",
    "super_agent_a.load_weights('model_mnist_1epoch_adam5e-5_2.h5py')\n",
    "\n",
    "super_agent_b = create_mnist_cnn_model()\n",
    "super_agent_b.load_weights('model_mnist_1epoch_adam5e-5.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_sparse, data_y = next(val_data_generator)\n",
    "\n",
    "true_categories = data_y.argmax(axis=1)\n",
    "\n",
    "predictions_a = super_agent_a.predict(x_test).argmax(axis=1)\n",
    "predictions_b = super_agent_b.predict(x_test).argmax(axis=1)\n",
    "predictions_judge = judge.predict(data_x_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreement = predictions_a != predictions_b\n",
    "\n",
    "resolution = predictions_judge[disagreement, predictions_a[disagreement]] > predictions_judge[disagreement, predictions_b[disagreement]]\n",
    "\n",
    "res = predictions_b[disagreement]\n",
    "res[resolution] = predictions_a[disagreement][resolution]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37950138504155123"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(res, true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23822714681440443"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_a[disagreement], true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6232686980609419"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_b[disagreement], true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9229"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_a, true_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9368"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predictions_b, true_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_category_judge = predictions_judge.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21329639889196675"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(predicted_category_judge[disagreement], true_categories[disagreement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disagreement.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_combined = predictions_a.copy()\n",
    "all_preds_combined[disagreement] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  9280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.928"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(all_preds_combined, true_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
